{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "tweet-sentiment-roberta-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13d3bbffd97243d89bfb893a2cacb4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff187be4241a42f69317ad976c95bacf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3de1c27a1d7246b5917e50da3efa6d12",
              "IPY_MODEL_c9373399a5564bd0aa0b1e0b8713d2eb"
            ]
          }
        },
        "ff187be4241a42f69317ad976c95bacf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3de1c27a1d7246b5917e50da3efa6d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8194a191f34a470ba3edf7f72903e6d9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ca95a5cda2248c2b8d8a928e2d36714"
          }
        },
        "c9373399a5564bd0aa0b1e0b8713d2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4cfa70d8d27d4e4db0d0be0d180df5ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:02&lt;00:00, 302kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9910b8c970ac416eb050aef3e5e523e9"
          }
        },
        "8194a191f34a470ba3edf7f72903e6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ca95a5cda2248c2b8d8a928e2d36714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cfa70d8d27d4e4db0d0be0d180df5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9910b8c970ac416eb050aef3e5e523e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57f7c44b531a4b02bc7d7b540f1c8ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7b19127ac1647b88e15010aac8b41ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aed6e860d5c84f9680d7b59a5fb93fde",
              "IPY_MODEL_14358c3252114b8fa333f8d24bfd8c33"
            ]
          }
        },
        "e7b19127ac1647b88e15010aac8b41ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aed6e860d5c84f9680d7b59a5fb93fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95ef028fb9634c519a178f3629ebe1dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d063f960e8a4ae999207987da03930e"
          }
        },
        "14358c3252114b8fa333f8d24bfd8c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b45c42aee7e0449f9b428aa9bc07b0fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:01&lt;00:00, 250kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8ca9ba605e04550abddf373ec12123c"
          }
        },
        "95ef028fb9634c519a178f3629ebe1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d063f960e8a4ae999207987da03930e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b45c42aee7e0449f9b428aa9bc07b0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8ca9ba605e04550abddf373ec12123c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a9adda77dc84ba9983852ee3e1eeb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8b70bcf12c44ee9ab8ec48d7d953087",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_118c39f7c6e84e3bbec4ab366d5421a8",
              "IPY_MODEL_8b85d2b94f364a34ab8c0c6c3001533a"
            ]
          }
        },
        "f8b70bcf12c44ee9ab8ec48d7d953087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "118c39f7c6e84e3bbec4ab366d5421a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b15c3aa240024fbca9c608cda826e44b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7273b9d77dfe422eb73e4f0c2fff79ed"
          }
        },
        "8b85d2b94f364a34ab8c0c6c3001533a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_168a897c535a43acac54e439cfbec534",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.46MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_333ee47df6ad4c43a0efa95388f8b44b"
          }
        },
        "b15c3aa240024fbca9c608cda826e44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7273b9d77dfe422eb73e4f0c2fff79ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "168a897c535a43acac54e439cfbec534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "333ee47df6ad4c43a0efa95388f8b44b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f8f3f0a87f54ad58e80a1fc8a040812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94183d6850154355943da43a51d74d35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1be5b22ab2d94fbca5b4fc4e31388f91",
              "IPY_MODEL_0af4b31fc553438083e151e820da7675"
            ]
          }
        },
        "94183d6850154355943da43a51d74d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1be5b22ab2d94fbca5b4fc4e31388f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31d793ea577443b69c8be5ed4ce6f695",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65b9b62e5af84b339e60c3fd330e6af3"
          }
        },
        "0af4b31fc553438083e151e820da7675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a06502f65b24cd79edc7fd5b265a5b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 13.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94198d881d2548f3ae72dd89823f9457"
          }
        },
        "31d793ea577443b69c8be5ed4ce6f695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65b9b62e5af84b339e60c3fd330e6af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a06502f65b24cd79edc7fd5b265a5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94198d881d2548f3ae72dd89823f9457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5d5f86533af4b01b185604a8c18cb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_175ebacaa6274bcdabdabd3b2a1d9f9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7fa1e4924a142d8816f183cf56c1c88",
              "IPY_MODEL_4548474fa71842809a37e4cc9194c2bd"
            ]
          }
        },
        "175ebacaa6274bcdabdabd3b2a1d9f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7fa1e4924a142d8816f183cf56c1c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d56309a9a3744ea6be748e6ba17d6ea7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97b39b796b5646d688e993770c7985c1"
          }
        },
        "4548474fa71842809a37e4cc9194c2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30201002ec3b4a66a51f1151a0f307ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:10&lt;00:00, 47.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c7001fcfab54b2da57c38cb9408a44d"
          }
        },
        "d56309a9a3744ea6be748e6ba17d6ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97b39b796b5646d688e993770c7985c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30201002ec3b4a66a51f1151a0f307ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c7001fcfab54b2da57c38cb9408a44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51c0369f88294a2fbcc3863bb8d39a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4f03e4538d64566b2c2e012767320a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b84a79d65f546558ded9a32c70a3aeb",
              "IPY_MODEL_e001145491dd466f831dcd6d018247e4"
            ]
          }
        },
        "d4f03e4538d64566b2c2e012767320a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b84a79d65f546558ded9a32c70a3aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fb49cf853fc418e9f4d208f18bf5932",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9206b4b727ed41ce8c7673320816ca27"
          }
        },
        "e001145491dd466f831dcd6d018247e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_131ee625a2514ae2b084e97d09c29ac0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:46&lt;00:00, 10.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a61b0f99badf44068ebec6370074d71f"
          }
        },
        "2fb49cf853fc418e9f4d208f18bf5932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9206b4b727ed41ce8c7673320816ca27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "131ee625a2514ae2b084e97d09c29ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a61b0f99badf44068ebec6370074d71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsYgYVHiINun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93187de-4a18-4647-8e5f-45904ed09a23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#change dir to your project folder\n",
        "%cd /content/drive/My Drive/Colab Notebooks/kaggle/tweet-sentiment\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/kaggle/tweet-sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv7qx2iXQZ6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dcc57c-5ea2-4a6c-abaa-25b06869657d"
      },
      "source": [
        "!ls -R\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".:\n",
            "'Data_down_tweet sentiment.ipynb'   roberta_whole2.pth\n",
            "'download_tweet sentiment.ipynb'    roberta_whole.pth\n",
            " input\t\t\t\t   'TensorFlow roBERTa - [0.712] (1).ipynb'\n",
            " roberta_fold1.pth\t\t   'TensorFlow roBERTa - [0.712].ipynb'\n",
            " roberta_whole1.pth\t\t    tweet-sentiment-roberta-pytorch.ipynb\n",
            "\n",
            "./input:\n",
            "tf-roberta  tweet-sentiment-extraction\n",
            "\n",
            "./input/tf-roberta:\n",
            "config-roberta-base.json  pretrained-roberta-base.h5\n",
            "merges-roberta-base.txt   vocab-roberta-base.json\n",
            "\n",
            "./input/tweet-sentiment-extraction:\n",
            "clean_train.csv  error_train.csv  sample_submission.csv  test.csv  train.csv\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szASIwcMRdB3"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "O5LtsA-lRdB5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch \n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "import tokenizers\n",
        "from transformers import RobertaModel, RobertaForQuestionAnswering, RobertaConfig, RobertaTokenizer\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlvEp4cM2KBA"
      },
      "source": [
        "# test out basics of roberta  \n",
        "# https://huggingface.co/transformers/model_doc/roberta.html#robertaforquestionanswering\n",
        "Test =False\n",
        "if Test:\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "    text = \"Jim is happy, but not me\" \n",
        "    sent_text = 'negative ' + \"Jim is happy, but not me\"\n",
        "    selected_text =  \"happy, but not me\"\n",
        "\n",
        "    text = [\"I win\"]\n",
        "    selected_text =  \"I win\"\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors='pt', pad_to_max_length=True, truncation=True, max_length=10)\n",
        "    start_positions = torch.tensor([1])\n",
        "    end_positions = torch.tensor([2])\n",
        "\n",
        "    model = RobertaForQuestionAnswering.from_pretrained('roberta-base')\n",
        "    outputs = model(**inputs)\n",
        "    # outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs.loss\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "    print(inputs, '\\n', outputs)\n",
        "# outputs\n",
        "# tokenizer.encode('negative'+\"Jim is happy, but not me\", return_tensors='pt')\n",
        "# inputs\n",
        "# outputs.start_logits.squeeze(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnT19flRdCA"
      },
      "source": [
        "# Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "M6MtpB7RRdCA"
      },
      "source": [
        "def seed_everything(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed = 42\n",
        "seed_everything(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ShzS94DRdCH"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScW55-ijFLJ4"
      },
      "source": [
        "### Add  token_len, start_idx, end_idx to training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-yibjHdCCz"
      },
      "source": [
        "cleaned = True\n",
        "if cleaned:\n",
        "    train_df = pd.read_csv('input/tweet-sentiment-extraction/clean_train.csv')\n",
        "else:\n",
        "    train_df = pd.read_csv('input/tweet-sentiment-extraction/train.csv')\n",
        "train_df['text'] = train_df['text'].astype(str)\n",
        "train_df['selected_text'] = train_df['selected_text'].astype(str)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_v7_fZC4Xjx"
      },
      "source": [
        "if 'token_len' not in train_df:  \n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    def token_length(row):\n",
        "        texto = \" \" + \" \".join(row.text.lower().split())\n",
        "        text = tokenizer(texto)['input_ids']\n",
        "        return len(text)\n",
        "    train_df['token_len'] = train_df.apply(token_length, axis=1)\n",
        "    print('max train token length: ', train_df.token_len.max())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7gj6gx8cV6a"
      },
      "source": [
        "if 'start_idx' not in train_df:   \n",
        "    # token level index \n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    def find_idx(row, p_token=False):\n",
        "        # tokenizer should not use padding since actual length is used\n",
        "        texto = \" \" + \" \".join(row.text.lower().split())\n",
        "        sel_to = \" \" + \" \".join(row.selected_text.lower().split())\n",
        "        text = tokenizer(texto)['input_ids']\n",
        "        sel_t = tokenizer(sel_to)['input_ids']\n",
        "        if p_token:\n",
        "            print(text, '\\n', sel_t)\n",
        "        # for very long sublist finding \n",
        "        # see https://stackoverflow.com/questions/7100242/python-numpy-first-occurrence-of-subarray\n",
        "        # we will just use rolling windows for tweet data\n",
        "        i = 1\n",
        "        while i<=len(text)-len(sel_t)+1:\n",
        "            if text[i] == sel_t[1]:\n",
        "                # print(i, text[i:i+len(sel_t)-2], sel_t[1:len(sel_t)-1])\n",
        "                if text[i:i+len(sel_t)-2] == sel_t[1:len(sel_t)-1]:\n",
        "                    start_idx = i\n",
        "                    end_idx = i+len(sel_t)-3\n",
        "                    return start_idx, end_idx\n",
        "                \n",
        "            i+=1\n",
        "        # Error in selected_text, this should be corrected using character level index\n",
        "        # idea 1: remove incomplete words in selected_text\n",
        "        # idea 2: complete the words\n",
        "        # idea 3: remove these rows\n",
        "        return 0, 0 \n",
        "     \n",
        "    train_df['start_idx'] = train_df.apply(lambda x: find_idx(x)[0], axis=1)\n",
        "    train_df['end_idx'] = train_df.apply(lambda x: find_idx(x)[1], axis=1)\n",
        "\n",
        "#=============================================================\n",
        "# character level index\n",
        "# def find_start(row):\n",
        "#     return row.text.find(row.selected_text)\n",
        "# def find_end(row):\n",
        "#     return  row.start_idx + len(row.selected_text)\n",
        "# if 'start_idx' not in train_df:\n",
        "#     train_df['start_idx'] = train_df.apply(lambda row: row.text.find(row.selected_text), axis=1)  # along column\n",
        "#     train_df['end_idx'] = train_df.apply(find_end, axis=1)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXyJYzERQh_2"
      },
      "source": [
        "### **Error in training labels** \n",
        "?? **convert_tokens_to_string** might solve the subwords error ??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5MKx-6zUp78"
      },
      "source": [
        "Test =False\n",
        "if Test:\n",
        "    error_train_df = train_df[train_df.start_idx ==0]\n",
        "    error_train_df\n",
        "# error_train_df.to_csv('input/tweet-sentiment-extraction/error_train.csv')\n",
        "    print(error_train_df.iloc[0].text, '\\n', error_train_df.iloc[0].selected_text)\n",
        "    find_idx(error_train_df.iloc[0], p_token=True)\n",
        "    print('**----- selected text wrong -----**')\n",
        "\n",
        "\n",
        "    print(error_train_df.iloc[2593].text, '\\n', error_train_df.iloc[2593].selected_text)\n",
        "    find_idx(error_train_df.iloc[2593], p_token=True)\n",
        "    print('**----- selected text missing a parenthesis -----**')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyy62tI8dr_K"
      },
      "source": [
        "- The error data is droped because\n",
        "* the error is not a structured and there is no easy fix\n",
        "* drop 2594/27481 <10% is not hurting too much"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CZTWnxSUh8l"
      },
      "source": [
        "train_df_clean = train_df[train_df.start_idx !=0]\n",
        "train_df_clean.reset_index(drop=True, inplace=True)\n",
        "del train_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9_C7QLBfJbN"
      },
      "source": [
        "### Torch data class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y6xRY4b9RdCI"
      },
      "source": [
        "class TweetDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, max_len=96):\n",
        "        self.df = df\n",
        "        self.max_len = max_len\n",
        "        self.labeled = 'selected_text' in df\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")            \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        # tokenizer should not use padding since actual length is used\n",
        "        text_o =  \" \" + \" \".join((row.text + ' '+ row.sentiment).lower().split())\n",
        "        data = self.tokenizer(text_o, \n",
        "                         return_tensors='pt', \n",
        "                         pad_to_max_length=True, \n",
        "                         truncation=True, \n",
        "                         max_length=self.max_len)\n",
        "        # \n",
        "        # since return_tensors='pt' will produce batched result but\n",
        "        # dataloaders only feed in one row at a time. so we should remove \n",
        "        # batch dimension In order to have auto batching working properly\n",
        "        for key in data.keys():\n",
        "            data[key]= data[key].squeeze()\n",
        "\n",
        "        # if we do not require  return_tensors='pt', tokenizer produce list; we need\n",
        "        #for key in data.keys():\n",
        "        #    data[key] = torch.tensor(data[key]) \n",
        "        \n",
        "        if self.labeled:\n",
        "            data['token_len'] = row.token_len\n",
        "            data['start_idx'] = row.start_idx\n",
        "            data['end_idx'] = row.end_idx\n",
        "\n",
        "            \"\"\"\n",
        "            compute start_idx and end_idx is time consuming, so we move it \n",
        "            to operate after loading df, and saving as columns in df\n",
        "            \"\"\"\n",
        "            # ## old code\n",
        "            # sel_o = \" \" + \" \".join(row.selected_text.lower().split())\n",
        "            # sel_token = self.tokenizer(sel_o, \n",
        "            #             truncation=True, \n",
        "            #             max_length=self.max_len)['input_ids']\n",
        "            # print(sel_o, '\\n', sel_token)\n",
        "            # data['start_idx'], data['end_idx'] = self.find_idx(text_token, sel_token)\n",
        "           \n",
        "        return data\n",
        "    # def find_idx(self, text, sel_t):\n",
        "    #   # for very long sublist finding \n",
        "    #     # see https://stackoverflow.com/questions/7100242/python-numpy-first-occurrence-of-subarray\n",
        "    #     # we will just use rolling windows for tweet data\n",
        "    #     i = 1\n",
        "    #     while i<=len(text)-len(sel_t)+1:\n",
        "    #         if text[i] == sel_t[1]:\n",
        "    #             if text[i:i+len(sel_t)-2]== sel_t[1:len(sel_t)-1]:\n",
        "    #                 start_idx = i\n",
        "    #                 print(i)\n",
        "    #                 end_idx = i+len(sel_t)-3\n",
        "    #                 return start_idx, end_idx\n",
        "    #         i+=1\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "#==============================================================  \n",
        "# auto batching is tricky when data are in different format, we could write a\n",
        "# function to replace default collate_fn\n",
        "def customer_batch(data):\n",
        "    pass\n",
        "\n",
        "#==============================================================    \n",
        "        \n",
        "def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n",
        "    train_df = df.iloc[train_idx]\n",
        "    val_df = df.iloc[val_idx]\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        TweetDataset(train_df), \n",
        "        batch_size=batch_size, \n",
        "        #collate_fn= customer_batch,\n",
        "        shuffle=True, \n",
        "        num_workers=1,\n",
        "        drop_last=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        TweetDataset(val_df), \n",
        "        batch_size=batch_size, \n",
        "        #collate_fn= customer_batch,\n",
        "        shuffle=False, \n",
        "        num_workers=1)\n",
        "\n",
        "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
        "\n",
        "    return dataloaders_dict\n",
        "\n",
        "#==============================================================    \n",
        "\n",
        "def get_test_loader(df, batch_size=32):\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        TweetDataset(df), \n",
        "        batch_size=batch_size, \n",
        "        #collate_fn= customer_batch,\n",
        "        shuffle=False, \n",
        "        num_workers=1)    \n",
        "    return loader"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "13d3bbffd97243d89bfb893a2cacb4f4",
            "ff187be4241a42f69317ad976c95bacf",
            "3de1c27a1d7246b5917e50da3efa6d12",
            "c9373399a5564bd0aa0b1e0b8713d2eb",
            "8194a191f34a470ba3edf7f72903e6d9",
            "8ca95a5cda2248c2b8d8a928e2d36714",
            "4cfa70d8d27d4e4db0d0be0d180df5ec",
            "9910b8c970ac416eb050aef3e5e523e9",
            "57f7c44b531a4b02bc7d7b540f1c8ec7",
            "e7b19127ac1647b88e15010aac8b41ed",
            "aed6e860d5c84f9680d7b59a5fb93fde",
            "14358c3252114b8fa333f8d24bfd8c33",
            "95ef028fb9634c519a178f3629ebe1dc",
            "5d063f960e8a4ae999207987da03930e",
            "b45c42aee7e0449f9b428aa9bc07b0fc",
            "d8ca9ba605e04550abddf373ec12123c",
            "9a9adda77dc84ba9983852ee3e1eeb72",
            "f8b70bcf12c44ee9ab8ec48d7d953087",
            "118c39f7c6e84e3bbec4ab366d5421a8",
            "8b85d2b94f364a34ab8c0c6c3001533a",
            "b15c3aa240024fbca9c608cda826e44b",
            "7273b9d77dfe422eb73e4f0c2fff79ed",
            "168a897c535a43acac54e439cfbec534",
            "333ee47df6ad4c43a0efa95388f8b44b",
            "4f8f3f0a87f54ad58e80a1fc8a040812",
            "94183d6850154355943da43a51d74d35",
            "1be5b22ab2d94fbca5b4fc4e31388f91",
            "0af4b31fc553438083e151e820da7675",
            "31d793ea577443b69c8be5ed4ce6f695",
            "65b9b62e5af84b339e60c3fd330e6af3",
            "7a06502f65b24cd79edc7fd5b265a5b4",
            "94198d881d2548f3ae72dd89823f9457"
          ]
        },
        "id": "7lkc6pBt0JC_",
        "outputId": "c90d8732-7430-4314-b330-9aeda6818e8a"
      },
      "source": [
        "\"\"\"Test the dataloaders\n",
        "\"\"\"\n",
        "Test = True\n",
        "i=1\n",
        "if Test:\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=777*32, random_state=seed)\n",
        "    for train_idx, val_idx in sss.split(train_df_clean, train_df_clean.sentiment):\n",
        "        # print(train_idx, val_idx)\n",
        "        \n",
        "        data_loader = get_train_val_loaders(train_df_clean, train_idx, val_idx, batch_size=2)['train']\n",
        "        for data in data_loader:\n",
        "            if i < 2:\n",
        "                #print(data)\n",
        "                i += 1\n",
        "                \n",
        "            # decode convert token ids to text\n",
        "            tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")  \n",
        "            print( tokenizer.decode(data['input_ids'][0][1:5]) )\n",
        "            break\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13d3bbffd97243d89bfb893a2cacb4f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57f7c44b531a4b02bc7d7b540f1c8ec7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a9adda77dc84ba9983852ee3e1eeb72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8f3f0a87f54ad58e80a1fc8a040812",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " like double posting on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "L7yF8o2lK9Yu",
        "outputId": "b080cd4a-039f-44be-d4df-fe01843bbf8e"
      },
      "source": [
        "train_df_clean"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>token_len</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24882</th>\n",
              "      <td>24882</td>\n",
              "      <td>8f5adc47ec</td>\n",
              "      <td>http://twitpic.com/663vr - Wanted to visit the...</td>\n",
              "      <td>were too late</td>\n",
              "      <td>negative</td>\n",
              "      <td>23</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24883</th>\n",
              "      <td>24883</td>\n",
              "      <td>a208770a32</td>\n",
              "      <td>in spoke to you yesterday and u didnt respond...</td>\n",
              "      <td>in spoke to you yesterday and u didnt respond ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24884</th>\n",
              "      <td>24884</td>\n",
              "      <td>b78ec00df5</td>\n",
              "      <td>enjoy ur night</td>\n",
              "      <td>enjoy</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24885</th>\n",
              "      <td>24885</td>\n",
              "      <td>f67aae2310</td>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>Yay good for both of you.</td>\n",
              "      <td>positive</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24886</th>\n",
              "      <td>24886</td>\n",
              "      <td>ed167662a5</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>positive</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24887 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0      textID  ... start_idx end_idx\n",
              "0               0  cb774db0d1  ...         1      10\n",
              "1               1  549e992a42  ...         1       3\n",
              "2               2  088c60f138  ...         4       5\n",
              "3               3  9642c003ef  ...         4       6\n",
              "4               4  358bd9e861  ...         1       4\n",
              "...           ...         ...  ...       ...     ...\n",
              "24882       24882  8f5adc47ec  ...        19      21\n",
              "24883       24883  a208770a32  ...         1      14\n",
              "24884       24884  b78ec00df5  ...         1       1\n",
              "24885       24885  f67aae2310  ...         1       8\n",
              "24886       24886  ed167662a5  ...         1       7\n",
              "\n",
              "[24887 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZep2SM2LANu",
        "outputId": "b8d753ed-e60a-469c-81a7-23f19cb3fdf6"
      },
      "source": [
        "24887/32"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "777.71875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oix6ns76RdCL"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MvpKKwrlRdCM"
      },
      "source": [
        "class TweetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TweetModel, self).__init__()\n",
        "  \n",
        "        self.roberta = RobertaForQuestionAnswering.from_pretrained('roberta-base')\n",
        "        # self.dropout = nn.Dropout(0.2)\n",
        "        # self.fc = nn.Linear(config.hidden_size, 2)\n",
        "        # nn.init.normal_(self.fc.weight, std=0.02)\n",
        "        # nn.init.normal_(self.fc.bias, 0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.roberta(**inputs)\n",
        "         \n",
        "        # x = torch.stack([hs[-1], hs[-2], hs[-3], hs[-4]])\n",
        "        # x = torch.mean(x, 0)\n",
        "        # x = self.dropout(x)\n",
        "        # x = self.fc(x)\n",
        "        # start_logits, end_logits = x.split(1, dim=-1)\n",
        "        # start_logits = start_logits.squeeze(-1)\n",
        "        # end_logits = end_logits.squeeze(-1)\n",
        "                \n",
        "        return outputs.start_logits, outputs.end_logits\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pg2wsE0RdCP"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TVirnKouRdCQ"
      },
      "source": [
        "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # start_logits/end_logits has dimension: batch * text_length\n",
        "    # start_positions/end_positions : batch * 1\n",
        "    start_loss = ce_loss(start_logits, start_positions)\n",
        "    end_loss = ce_loss(end_logits, end_positions)    \n",
        "    total_loss = start_loss + end_loss\n",
        "    return total_loss\n",
        "\n",
        "def loss_fn1(start_logits, end_logits, start_positions, end_positions):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # start_logits/end_logits has dimension: batch * text_length\n",
        "    # start_positions/end_positions : batch * 1\n",
        "    start_loss = ce_loss(start_logits, start_positions)\n",
        "    end_loss = ce_loss(end_logits, end_positions)   \n",
        "    length =  (end_positions - start_positions).abs().float()\n",
        "    # when length is large, we do not really care so much on every position, take average \n",
        "    total_loss = (start_loss + end_loss)/length # + 0.1* length\n",
        "    return total_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYZf3tbeHsVu"
      },
      "source": [
        "- Jaccard distance and Binary Cross Entropy are similar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "F31jz_hldfv5",
        "outputId": "b1221a6d-8693-4145-9101-6efc71194409"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def jaccard_distance_loss(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
        "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
        "    Jaccard_smoothed = \n",
        "    \n",
        "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
        "    \n",
        "    \"\"\"\n",
        "    intersection= (y_true * y_pred).abs().sum(dim=1)\n",
        "    union = torch.sum(y_true.abs() + y_pred.abs(), dim=1) -intersection\n",
        "    jac = (intersection + smooth) / (union + smooth)\n",
        "    return (1 - jac) * smooth\n",
        "\n",
        "\n",
        "# Test and plot\n",
        "y_pred = torch.from_numpy(np.array([np.arange(-10, 10+0.1, 0.1)]).T)\n",
        "y_true = torch.from_numpy(np.zeros(y_pred.shape))\n",
        "name='jaccard_distance_loss'\n",
        "loss = jaccard_distance_loss(y_true,y_pred).numpy()\n",
        "plt.title(name)\n",
        "plt.plot(y_pred.numpy(),loss)\n",
        "plt.xlabel('abs prediction error')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "    \n",
        "name='binary cross entropy'\n",
        "loss = torch.nn.functional.binary_cross_entropy(\n",
        "       y_true,y_pred, reduction='none').mean(-1).numpy()\n",
        "plt.title(name)\n",
        "plt.plot(y_pred.numpy(),loss)\n",
        "plt.xlabel('abs prediction error')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "    \n",
        "# Test\n",
        "print(\"TYPE                 |Almost_right |half right |extra selected |all_wrong\")\n",
        "y_true = torch.from_numpy(np.array([[0,0,1,0],[0,0,1,0],[0,0,1,0],[0,0,1.,0.]]))\n",
        "y_pred = torch.from_numpy(np.array([[0,0,0.9,0],[0,0,0.1,0],[1,1,1,1],[1,1,0,1]]))\n",
        "\n",
        "y_true = torch.from_numpy(np.array([[0,0,1],[0,0,1],[0,0,1],[0,0,1.]]))\n",
        "y_pred = torch.from_numpy(np.array([[0,0,0.9],[0,0,0.1],[1,1,1],[1,1,0]]))\n",
        "r1 = jaccard_distance_loss(\n",
        "    y_true,\n",
        "    y_pred,).numpy()\n",
        "print('jaccard_distance_loss',r1)\n",
        "print('jaccard_distance_loss scaled',r1/r1.max())\n",
        "assert r1[0]<r1[1]\n",
        "assert r1[1]<r1[2]\n",
        "\n",
        "r2 = torch.nn.functional.binary_cross_entropy(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    reduction='none').mean(-1).numpy()\n",
        "print('binary_crossentropy',r2)\n",
        "print('binary_crossentropy_scaled',r2/r2.max())\n",
        "assert r2[0]<r2[1]\n",
        "assert r2[1]<r2[2]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUdfb/8deh995LpFdBxNDsBQW7qGvvruiu/nb96koRC7a1rGV37bg2rLh0ERWwrBUFLKFD6KH3Tkg5vz/uZXeME0xIJjNJ3s/HYx7c+7mfe+fMnWFObpnzMXdHRESkIMrEOwARESn+lExERKTAlExERKTAlExERKTAlExERKTAlExERKTAlEwkoZnZcjPrm8uy48xsYVHHJCK/pmQixZa7f+nu7eMdR0liZq+Z2YPxjkOKHyUTkRwsEJP/G2ZWLhbbLSrFPX6JHSUTKQ56mNk8M9tqZq+aWSUAMzvRzNIOdApPif3FzFLMbLuZjYroW9vMJpnZxnA7k8ysWcS6n5vZQ2b2NbAHuN3MZkUGYWa3mdmEaAGaWZ0wtjXh9sdHxmhmg81sHfCqmVU0s7+HfdeE0xXD/vXC2LaZ2RYz+/JAYgu3sdrMdprZQjM7JZdYKprZ42a20szWm9kLZlY5Rzy3m9kGM1trZteGywYClwODzGyXmb0fsV8Hm1kKsNvMypnZOWY2N4zzczPrmON9GJrLezbHzM6O6FvezDaZ2ZF5+SBI4lIykeLgcqAf0BpoB9x1kL4XAf2BlkBX4JqwvQzwKnAYkATsBZ7Jse6VwECgOvBPoGXkl2S4fGQuz/sGUAXoDDQAnopY1gioEz73QGAY0BvoBhwB9Ix4TbcDaUB9oCFwJ+Bm1h64Bejh7tXD/bE8l1geIdhP3YA2QFPgnhzx1AzbrweeNbPa7j4CeAt4zN2rufvZEetcCpwJ1AJaAe8At4ZxTgbeN7MKEf1ze89GAldE9DsDWOvuP+byWqS4cHc99EjYB8EX5k0R82cAS8LpE4G0HH2viJh/DHghl+12A7ZGzH8O3J+jz/PAQ+F0Z2ArUDHKthoD2UDtKMtOBPYDlSLalgBnRMz3A5aH0/cDE4A2ObbTBtgA9AXKH2R/GbAbaB3R1gdYFhHPXqBcxPINQO9w+jXgwSjvwXUR83cD70XMlwFWAyfm4T1rAuwEaoTzo4FB8f6c6VHwh45MpDhYFTG9guALKTfrIqb3ANUAzKyKmb1oZivMbAfwBVDLzMrm8jwArwOXmZkRHJW85+7pUZ6zObDF3bfmEtNGd98XMd8kfB3RXtPfgFRgipktNbMhAO6eSnAkMBzYYGbvmlm0/VCf4AhpVngKahvwUdh+wGZ3z4yY/+9+OojIffOL+N09O1zeNJf+/3197r4G+Bq4wMxqAacTHA1JMadkIsVB84jpJGDNIWzjdqA90MvdawDHh+0W0ecXJbTdfTrBUcVxwGUEp7KiWQXUCb8co8lZmnsNwSmvA/77mtx9p7vf7u6tgHOA2w5cG3H3t9392HBdBx6N8lybCI48Ort7rfBR091/K1nkFmu09l/EHybb5gRHJwcc7D17neBU1++Ab909cj0pppRMpDi42cyamVkdgusNow5hG9UJvmS3hdu5N4/rjSS4tpLh7l9F6+Dua4EPgefCC/3lzez4aH1D7wB3mVl9M6tHcD3jTQAzO8vM2oRf0NuBLCDbzNqb2cnhhfp94WvJjhJLNvAS8JSZNQi32dTM+uXx9a4nuCZyMO8BZ5rZKWZWniBRpwPfRPQ52Hs2HugO/Jncr0FJMaNkIsXB28AUYCnB9YZD+R3E34HKBH+5Tyc49ZMXbwCHE37ZH8SVQAawgOAaxK0H6fsgMBNIAWYDP/C/19QWmAbsAr4FnnP3z4CKBBfWNxGcymsADM1l+4MJTpVND0/pTSM4KsuLl4FO4Smy8dE6uPtCgiOLp8N4zgbOdvf9Ed1yfc/cfS8whuAmibF5jEsSnLlrcCyR3IS31G4Aurv74njHUxyY2XLg9+4+7SB97gHaufsVufWR4kU/QBI5uD8AM5RICk946ut6gqM5KSGUTERyEf6FbcB5cQ6lxDCzGwhOOb7h7l/EOx4pPDrNJSIiBaYL8CIiUmCl9jRXvXr1vEWLFvEOQ0SkWJk1a9Ymd6+fs73UJpMWLVowc+bMeIchIlKsmNmKaO06zSUiIgWmZCIiIgWmZCIiIgWmZCIiIgWmZCIiIgUW12RiZq+EQ4fOiWirY2ZTzWxx+G/tsN3M7J9mlmrBsKzdI9a5Ouy/2MyujsdrEREpzeJ9ZPIawRCrkYYAn7h7W+CTcB6CQXTaho+BBKPgHajzcy/Qi2D403sPJCARESkacU0mYW2eLTmazyUYPIfw3/Mi2kd6YDrBKHmNCYY8neruB0a6m8qvE5SISKm3cN1OHvtoAbEooxXvI5NoGoaDDUEwbkPDcLopvxwKNC1sy639V8xsoJnNNLOZGzduLNyoRUQS1P7MbP4+bRFnPf0l785Yxdrt+357pXxK6F/Au7ubWaGlUHcfAYwASE5OVoVLESnxfl61jUGjU1i4fifndmvCPWd1om61ioX+PImYTNabWWN3XxuextoQtq/ml+NKNwvbVgMn5mj/vAjiFBFJWHv3Z/Hk1IW8/NUyGlSvxMtXJ3NKx4a/veIhSsTTXBOBA3dkXQ1MiGi/KryrqzewPTwd9jFwWjj2dm3gtLBNRKRU+mbJJvr9/Qte+nIZl/RMYsptx8c0kUCcj0zM7B2Co4p6ZpZGcFfWI8B7ZnY9sAK4KOw+GTiDYGzrPcC1AO6+xcweAGaE/e5395wX9UVESrwd+zJ4ePIC3vl+JYfVrcI7N/SmT+u6RfLcpXZwrOTkZFfVYBEpKabNW8+w8bPZuDOd3x/Xiv/r247KFcoW+vOY2Sx3T87ZnojXTEREJI8270rnvvfnMfHnNXRoVJ0RVyZzRPNaRR6HkomISDHk7kz8eQ3DJ85lV3omt53ajptOaE2FcvG5FK5kIiJSzKzZtpe7xs/h0wUb6Na8Fo9d2JV2DavHNSYlExGRYiI723lnxkoenryArGzn7rM6cc3RLShbxuIdmpKJiEhxsGzTboaMSeG7ZVs4pk1dHh7QlaS6VeId1n8pmYiIJLDMrGxe+XoZT0xZRIVyZXj0gi5clNwcs/gfjURSMhERSVDz1+5g8JgUUtK2c2qnhjx43uE0rFEp3mFFpWQiIpJg0jOzePbTVJ77fAm1qpTn2cu6c0aXRgl3NBJJyUREJIH8sHIrg0ensHjDLs4/sil3n9WJ2lUrxDus36RkIiKSAPbsz+Txjxfx6jfLaFyjEq9e24OT2jeId1h5pmQiIhJnX6duYsjYFFZt2cuVvQ9jUP/2VK9UPt5h5YuSiYhInGzfm8FfP5jPqJmraFmvKqMG9qZXq6IpzFjYlExEROJgytx13DV+Dpt37+emE1pza9+2VCpf+IUZi4qSiYhIEdq4M53h78/lg5S1dGxcg5ev7kGXZjXjHVaBKZmIiBQBd2fcj6u5f9I89qRncUe/9gw8vhXlyybiGIX5p2QiIhJjq7ftZdi42Xy+cCPdk4LCjG0axLcwY2FLyGRiZu2BURFNrYB7gFrADcDGsP1Od58crjMUuB7IAv7k7hq6V0TiKjvbeeu7FTzy4QIcGH52J67skxiFGQtbQiYTd18IdAMws7LAamAcwVC9T7n745H9zawTcAnQGWgCTDOzdu6eVaSBi4iElm7cxZAxs/l++RaOa1uPvw7oQvM6iVOYsbAlZDLJ4RRgibuvOEgpgXOBd909HVhmZqlAT+DbIopRRAQICjO+9OUynpq2iErlyvC3C7ty4VHNEroUSmEoDsnkEuCdiPlbzOwqYCZwu7tvBZoC0yP6pIVtv2BmA4GBAElJSTELWERKp7lrtjN4TApzVu+gf+dG3H9eZxpUT8zCjIUtoW8jMLMKwDnAv8Om54HWBKfA1gJP5Gd77j7C3ZPdPbl+/fqFGquIlF77MrL428cLOOeZr1m3PZ3nL+/OC1ceVWoSCST+kcnpwA/uvh7gwL8AZvYSMCmcXQ00j1ivWdgmIhJTs1ZsYdDoFJZs3M0F3Ztx91kdqVUl8QszFrZETyaXEnGKy8wau/vacHYAMCecngi8bWZPElyAbwt8X5SBikjpsjs9k799vJDXv11Ok5qVef26npzQrvSe8UjYZGJmVYFTgRsjmh8zs26AA8sPLHP3uWb2HjAPyARu1p1cIhIrXyzayNCxs1mzfS9X92nBX/q1p1rFhP06LRIJ++rdfTdQN0fblQfp/xDwUKzjEpHSa9ue/Tz4wXxGz0qjVf2q/PvGPiS3qBPvsBJCwiYTEZFE8uHstdw9YS5b9+zn5pNa8/9OLt6FGQubkomIyEFs2LmPeyfM5cM56+jcpAavX9eDzk2Kf2HGwqZkIiIShbszelYaD34wn70ZWQzq354bjis5hRkLm5KJiEgOq7bs4c5xs/ly8SZ6tKjNIxd0pXX9avEOK6EpmYiIhLKznZHfLuexjxdiwAPndubyXodRpgQWZixsSiYiIkDqhp0MHjObWSu2ckK7+jw04HCa1S65hRkLm5KJiJRqGVnZjPhiKf+YtpgqFcvy5EVHMODIpiW+MGNhUzIRkVJrzurtDBqdwry1OzizS2OGn9OZ+tUrxjusYknJRERKnX0ZWfzjk8WM+GIpdapW4IUrjqL/4Y3iHVaxpmQiIqXKjOVbGDw6haWbdnNRcjOGndGJmlXKxzusYk/JRERKhV3pmTz20QJGfruCZrUr8+b1vTi2bb14h1ViKJmISIn32cINDBs7m7U79nHdMS35S792VKmgr7/CpL0pIiXW1t37eWDSPMb+uJo2Daox+qajOeqw2vEOq0RSMhGREsfdmTx7HfdOnMO2PRn86eQ23HxyGyqWU2HGWFEyEZESZcOOfdw1fg5T5q2nS9OajLyuF52a1Ih3WCWekomIlAjuzr9npvHAB/PYn5nN0NM7cP2xLSmnwoxFImGTiZktB3YCWUCmuyebWR1gFNCCYKTFi9x9qwU/Vf0HcAawB7jG3X+IR9wiUvRWbt7D0HEpfJ26mZ4t6/DoBV1pWa9qvMMqVRI2mYROcvdNEfNDgE/c/REzGxLODwZOJxj3vS3QC3g+/FdESrCsbOe1b5bz+McLKVvGePC8w7msZ5IKM8ZBoieTnM4FTgynXwc+J0gm5wIj3d2B6WZWy8wau/vauEQpIjG3eP1OBo1J4ceV2zipfX0eGtCFJrUqxzusUiuRk4kDU8zMgRfdfQTQMCJBrAMahtNNgVUR66aFbb9IJmY2EBgIkJSUFMPQRSRW9mdm88J/lvDMp6lUrViWv1/cjXO7NVFhxjhL5GRyrLuvNrMGwFQzWxC50N09TDR5FiakEQDJycn5WldE4i8lbRuDRqewYN1Ozj6iCfee3Yl61VSYMREkbDJx99XhvxvMbBzQE1h/4PSVmTUGNoTdVwPNI1ZvFraJSAmwd38Wf5+2iJe+XEr96hV56apkTu3U8LdXlCKTkPfMmVlVM6t+YBo4DZgDTASuDrtdDUwIpycCV1mgN7Bd10tESobpSzdz+j++4MUvlnJxj+ZMve0EJZIElKhHJg2BceE50HLA2+7+kZnNAN4zs+uBFcBFYf/JBLcFpxLcGnxt0YcsIoVp574MHvlwAW99t5KkOlV4+/e9OLqNCjMmqoRMJu6+FDgiSvtm4JQo7Q7cXAShiUgR+HTBeoaNm8P6Hfv4/bEtuf209lSuoFIoiSwhk4mIlE5bdu/n/vfnMv6nNbRrWI3nLj+aI5NUmLE4UDIRkbhzd95PWcvwiXPZuS+DP5/SlptPakOFcgl5WVeiUDIRkbhatz0ozDht/nqOaFaTRy/sRYdGKsxY3CiZiEhcuDvvzljFXz+YT0Z2Nned2ZFrj2lJWZVCKZaUTESkyK3YvJshY2bz7dLN9GlVl0cu6MJhdVWYsThTMhGRIpOV7bz69TIen7KQ8mXK8PD5XbikR3OVQikBlExEpEgsXBcUZvx51Tb6dmzAg+d1oVHNSvEOSwqJkomIxNT+zGye/SyV5z5PpXql8vzz0iM5u2tjHY2UMEomIhIzP63axqDRP7No/S7O69aEe87uTJ2qFeIdlsSAkomIFLq9+7N4YspCXvl6GQ1rVOKVa5I5uYPqaZVkSiYiUqi+WbKJIWNms3LLHi7vlcSQ0ztQvVL5eIclMaZkIiKFYse+DB6ePJ93vl9Fi7pVeHdgb3q3qhvvsKSIKJmISIFNm7eeYeNns3FnOjce34pb+7ZTYcZSRslERA7Zpl3p3Pf+PN7/eQ0dGlXnpauS6dqsVrzDkjhQMhGRfHN3Jvy0hvven8uu9ExuO7UdN53QWoUZS7GEe+fNrLmZfWZm88xsrpn9OWwfbmarzeyn8HFGxDpDzSzVzBaaWb/4RS9S8q3ZtpfrX5/JraN+okW9qkz+03H86ZS2SiSlXCIemWQCt7v7D+HQvbPMbGq47Cl3fzyys5l1Ai4BOgNNgGlm1s7ds4o0apESLjvbefv7lTzy4QKysp17zurE1Ue3UGFGARIwmYRjt68Np3ea2Xyg6UFWORd4193TgWVmlgr0BL6NebAipcSyTbsZMiaF75Zt4Zg2dXl4QFeS6laJd1iSQBIumUQysxbAkcB3wDHALWZ2FTCT4OhlK0GimR6xWhq5JB8zGwgMBEhKSopZ3CIlRWZWNi9/tYwnpy6iQrkyPHZBV36X3EylUORXEvYkp5lVA8YAt7r7DuB5oDXQjeDI5Yn8btPdR7h7srsn169fv1DjFSlp5q3ZwYDnvuHhDxdwQrv6TLvtBC5ShV/JRUIemZhZeYJE8pa7jwVw9/URy18CJoWzq4HmEas3C9tE5BCkZ2bxzKepPP/5EmpVKc+zl3XnjC6NlETkoBIumVjwiX0ZmO/uT0a0Nw6vpwAMAOaE0xOBt83sSYIL8G2B74swZJESY9aKrQwek0Lqhl2c370pd5/ZidoqzCh5kHDJhODayJXAbDP7KWy7E7jUzLoBDiwHbgRw97lm9h4wj+BOsJt1J5dI/uzZn8nfPl7Ia98sp3GNSrx6bQ9Oat8g3mFJMZJwycTdvwKiHU9PPsg6DwEPxSwokRLsq8WbGDI2hbSte7mqz2EM6t+BahUT7qtBEpw+MSKl1PY9GTw0eR7vzUyjZb2qvHdjH3q2rBPvsKSYUjIRKYU+mrOOuyfMYcvu/fzhxNb8+ZS2VCqvwoxy6JRMREqRjTvTGT5xLh/MXkunxjV49ZoeHN60ZrzDkhJAyUSkFHB3xv6wmvsnzWPv/izu6Neegce3onzZhP2pmRQzSiYiJdzqbXu5c+xs/rNoI0cdVptHL+hKmwbV4h2WlDBKJiIlVHa28+Z3K3j0wwU4MPzsTlzVpwVlVJhRYkDJRKQEWrJxF0PGpDBj+VaOa1uPvw7oQvM6KswosaNkIlKCZGRl89KXS/n7tMVULl+Wx393BBd0b6pSKBJzSiYiJcSc1dsZPCaFuWt2cPrhjbjv3M40qF4p3mFJKaFkIlLM7cvI4ulPF/PCf5ZSu0oFnr+8O6d3aRzvsKSUUTIRKcZmLt/CoDEpLN24mwuPasZdZ3akVhUVZpSip2QiUgztTg8KM77+7XKa1KzMyOt6cnw7jdEj8aNkIlLM/GfRRu4cO5s12/dydZ8W3NGvPVVVmFHiLE+fQDP7M/AqsBP4F8FQukPcfUoMYxORCNv27OeBSfMZ80MaretX5d839iG5hQozSmLI658z17n7P8ysH1CbYLyRNwAlE5Ei8OHstdw9YS5b9+znlpPacMvJbVSYURJKXpPJgZvUzwDeCAek0o3rIjG2Ycc+7pkwl4/mrqNzkxq8fl0POjdRYUZJPHlNJrPMbArQEhhqZtWB7NiFlX9m1h/4B1AW+Je7PxLnkEQOmbszelYaD0yax77MbAb378ANx7WknAozSoLKazK5HugGLHX3PWZWB7g2dmHlj5mVBZ4FTgXSgBlmNtHd58U3MpH8W7VlD3eOm82XizfRo0VtHrmgK63rqzCjJLa8JpM+wE/uvtvMrgC6ExwFJIqeQKq7LwUws3eBcwnGhRcpFrKynZHfLudvHy/EgAfO7czlvQ5TYUYpFvKaTJ4HjjCzI4DbCe7oGgmcEKvA8qkpsCpiPg3olbOTmQ0EBgIkJSUVTWQieZC6YSeDx8xm1oqtnNCuPn89vwtNa1WOd1gieZbXZJLp7m5m5wLPuPvLZnZ9LAOLBXcfAYwASE5O9jiHI0JGVjYv/mcJ//wklSoVy/LkRUcw4EgVZpTiJ6/JZKeZDSW4Jfg4MysDlI9dWPm2GmgeMd8sbBNJWHNWb+eO0SnMX7uDM7s2ZvjZnalfvWK8wxI5JHlNJhcDlxH83mSdmSUBf4tdWPk2A2hrZi0JksglBPGKJJx9GVn8fdpiXvpyKXWqVuDFK4+iX+dG8Q5LpEDylEzCBPIW0MPMzgK+d/eRsQ0t79w908xuAT4muDX4FXefG+ewRH7lu6WbGTJ2Nss27ebi5ObceUZHalZJpIN8kUOT13IqFxEciXxO8APGp83sDncfHcPY8sXdJwOT4x2HSDQ792Xw2EcLeWP6CprXqcyb1/fi2Lb14h2WSKHJ62muYUAPd98AYGb1gWlAwiQTkUT12cINDBs7m7U79nHdMS35S792VKmgwoxSsuT1E13mQCIJbQb0U1yRg9i6ez8PTJrH2B9X07ZBNcb84Wi6J9WOd1giMZHXZPKRmX0MvBPOX4xOKYlE5e58MHst906Yy/a9Gfzp5DbcfHIbKpZTYUYpufJ6Af4OM7sAOCZsGuHu42IXlkjxtH7HPu4aP4ep89bTpWlN3vx9Lzo2rhHvsERiLs8nbt19DDAmhrGIFFvuznszV/HgB/PZn5nN0NM7cP2xKswopcdBk4mZ7QSi/VLcAHd3/cklpd7KzXsYMjaFb5ZsplfLOjxyQVda1qsa77BEitRBk4m7Vy+qQESKm6xs57VvlvP4xwspW8Z4aMDhXNojSYUZpVTS/Ykih2DR+p0MGp3CT6u2cXKHBjw04HAa11RhRim9lExE8mF/ZjbPf76EZz5bTLWK5fjHJd0454gmKswopZ6SiUge/bxqG4PHpLBg3U7OPqIJw8/uRN1qKswoAkomIr9p7/4snpq2iH99uZT61Svy0lXJnNqpYbzDEkkoSiYiB/Htks0MHZvC8s17uLRnEkPP6ECNSirMKJKTkolIFDv2ZfDIhwt4+7uVHFa3Cm/f0IujW6swo0hulExEcvh0wXruHDuHDTv3ccNxLbnt1PZUrqBSKCIHo2QiEtq8K537J81jwk9raN+wOi9ceRTdmteKd1gixYKSiZR67s7En9dw3/vz2Lkvg1v7tuWPJ7ahQjmVQhHJq4RKJmb2N+BsYD+wBLjW3beZWQtgPrAw7Drd3W8K1zkKeA2oTFDJ+M/uHq0EjMivrN2+l7vGzeGTBRs4onktHrugK+0bqfCDSH4lVDIBpgJDw2F4HwWGAoPDZUvcvVuUdZ4HbgC+I0gm/YEPiyJYKb6ys513Z6zi4cnzycjO5q4zO3LtMS0pq1IoIockoZKJu0+JmJ0OXHiw/mbWGKjh7tPD+ZHAeSiZyEEs37SbIWNTmL50C31a1eWRC7pwWF0VZhQpiIRKJjlcB4yKmG9pZj8CO4C73P1LoCmQFtEnLWyLyswGAgMBkpKSCj1gSWyZWdm8+vVynpi6kPJlyvDI+V24uEdzlUIRKQRFnkzMbBrQKMqiYe4+IewzDMgE3gqXrQWS3H1zeI1kvJl1zu9zu/sIYARAcnKyrquUIgvW7WDw6BR+TttO344NePC8LjSqWSneYYmUGEWeTNy978GWm9k1wFnAKQcupLt7OpAeTs8ysyVAO2A10Cxi9WZhmwgA6ZlZPPvZEp77LJWalcvz9KVHclbXxjoaESlkCXWay8z6A4OAE9x9T0R7fWCLu2eZWSugLbDU3beY2Q4z601wAf4q4Ol4xC6J58eVWxk8JoVF63dxXrcm3HN2Z+pUrRDvsERKpIRKJsAzQEVgaviX44FbgI8H7jezDCAbuMndt4Tr/JH/3Rr8Ibr4Xurt2Z/JE1MW8crXy2hUoxKvXJPMyR1UmFEklhIqmbh7m1zacx1/3t1nAofHMi4pPr5J3cSQsbNZuWUPV/ROYnD/DlRXYUaRmEuoZCJyqLbvzeDhyfN5d8YqWtStwrsDe9O7Vd14hyVSaiiZSLE3Ze467ho/h0270rnxhFb8X992VCqvwowiRUnJRIqtTbvSGT5xLpNS1tKhUXX+dXUyXZupMKNIPCiZSLHj7oz/aTX3vT+PPelZ3H5qO248obUKM4rEkZKJFCtrtu1l2LjZfLZwI0cmBYUZ2zZUYUaReFMykWIhO9t56/uVPPrhArKynXvO6sTVR7dQYUaRBKFkIglv6cZdDBk7m++XbeHYNvV4+PwuNK9TJd5hiUgEJRNJWJlZ2fzrq2U8NXURFcqV4bELuvK75GYqhSKSgJRMJCHNW7ODQWN+Zs7qHZzWqSEPnHc4DWuoMKNIolIykYSSnpnFM5+m8vznS6hVpTzPXd6d0w9vpKMRkQSnZCIJY9aKoDBj6oZdnN+9KXef2YnaKswoUiwomUjc7U7P5PEpC3ntm+U0qVmZ167twYntG8Q7LBHJByUTiasvF29k6NjZpG3dy1V9DmNQ/w5Uq6iPpUhxo/+1Ehfb92Tw4Afz+PesNFrVq8p7N/ahZ8s68Q5LRA6RkokUuY/mrOPuCXPYsns/fzyxNX86pa0KM4oUcwlXzMjMhpvZajP7KXycEbFsqJmlmtlCM+sX0d4/bEs1syHxiVx+y4ad+/jjW7O46c1Z1K9WkQk3H8Og/h2USERKgEQ9MnnK3R+PbDCzTsAlQGegCTDNzNqFi58FTgXSgBlmNtHd5xVlwJI7d2fsD6u5f9I89mZkcUe/9gw8vhXlyybc3zIicogSNZlEcy7wrrunA8vMLBXoGS5LdfelAGb2bthXySQBpG3dw53j5vDFoo0cdVhtHr2gK20aVIt3WCJSyBI1mdxiZlcBM4Hb3X0r0BSYHtEnLaudFTIAABM/SURBVGwDWJWjvVe0jZrZQGAgQFJSUmHHLBGys503pq/g0Y8WAHDfOZ25svdhlFFhRpESKS7JxMymAY2iLBoGPA88AHj47xPAdYXxvO4+AhgBkJyc7IWxTfm1JRt3MXh0CjNXbOW4tvX46wAVZhQp6eKSTNy9b176mdlLwKRwdjXQPGJxs7CNg7RLEcrIymbEF0v5xyeLqVy+LI//7ggu6N5UpVBESoGEO81lZo3dfW04OwCYE05PBN42sycJLsC3Bb4HDGhrZi0JksglwGVFG7XMWb2dwWNSmLtmB2d0acTwczrToLoKM4qUFgmXTIDHzKwbwWmu5cCNAO4+18zeI7iwngnc7O5ZAGZ2C/AxUBZ4xd3nxiPw0mhfRhb//GQxL36xlNpVKvDCFd3pf3jjeIclIkXM3EvnpYPk5GSfOXNmvMMo1mYs38Lg0Sks3bSb3x3VjLvO7ETNKuXjHZaIxJCZzXL35JztiXhkIgluV3omj320gJHfrqBprcqMvK4nx7erH++wRCSOlEwkX/6zaCN3jp3Nmu17ueboFtzRrz1VVZhRpNTTt4DkybY9+7l/0jzG/rCa1vWrMvqmPhx1mAozikhAyUR+0+TZa7lnwhy27cnglpPacMvJbVRPS0R+QclEcrVhxz7unjCHj+eu5/CmNXj9up50blIz3mGJSAJSMpFfcXf+PSuNByfNY19mNoP7d+CG41pSToUZRSQXSibyC6u27GHo2Nl8lbqJni3q8MgFXWhVX4UZReTglEwEgKxsZ+S3y3nso4WUMXjgvMO5vGeSCjOKSJ4omQipG3YyaHQKP6zcxont6/PQgC40rVU53mGJSDGiZFKKZWRl88LnS3j601SqVCzLUxcfwXndVJhRRPJPyaSUmp22nTtG/8yCdTs5s2tj7junM/WqVYx3WCJSTCmZlDL7MrJ4atoiXvpiKfWqVeTFK4+iX+doQ8uIiOSdkkkp8t3SzQwZO5tlm3ZzcXJz7jyzIzUrqzCjiBSckkkpsHNfBo9+tIA3p6+keZ3KvPX7XhzTpl68wxKREkTJpIT7bMEGho2bzdod+7j+2Jbcflo7qlTQ2y4ihUvfKiXUlt37eWDSPMb9uJq2Daox5g9H0z2pdrzDEpESKqGSiZmNAtqHs7WAbe7ezcxaAPOBheGy6e5+U7jOUcBrQGVgMvBnL60jfhGUQpmUspbhE+eyfW8GfzqlLTef1JqK5VSYUURiJ6GSibtffGDazJ4AtkcsXuLu3aKs9jxwA/AdQTLpD3wYyzgT1fod+xg2bg7T5q+na7OavPn7XnRsXCPeYYlIKZBQyeQAC341dxFw8m/0awzUcPfp4fxI4DxKWTJxd0bNWMVDk+ezPzObO8/owHXHqDCjiBSdhEwmwHHAendfHNHW0sx+BHYAd7n7l0BTIC2iT1rYFpWZDQQGAiQlJRV60PGwcvMehoxN4Zslm+nVsg6PXtCVFvWqxjssESllijyZmNk0INqv5Ia5+4Rw+lLgnYhla4Ekd98cXiMZb2ad8/vc7j4CGAGQnJxcrK+rZGU7r369jMenLKRcmTL8dUAXLunRXIUZRSQuijyZuHvfgy03s3LA+cBREeukA+nh9CwzWwK0A1YDzSJWbxa2lWgL1+1k8JgUflq1jZM7NOChAYfTuKYKM4pI/CTiaa6+wAJ3/+/pKzOrD2xx9ywzawW0BZa6+xYz22FmvQkuwF8FPB2XqIvA/sxsnvs8lWc/S6V6pfL845JunHNEExVmFJG4S8Rkcgm/PMUFcDxwv5llANnATe6+JVz2R/53a/CHlNCL7z+v2sag0SksXL+Tc45owr1nd6KuCjOKSIJIuGTi7tdEaRsDjMml/0zg8BiHFTd792fx5NSFvPzVMhpUr8S/rkqmb6eG8Q5LROQXEi6ZyP98u2QzQ8amsGLzHi7rlcSQ0ztQo5IKM4pI4lEySUA79mXw8OQFvPP9Sg6rW4W3b+jF0a1VmFFEEpeSSYKZNm89w8bPZuPOdAYe34r/69uOyhVUCkVEEpuSSYLYvCud+96fx8Sf19C+YXVevDKZbs1rxTssEZE8UTKJM3dn4s9rGD5xLrvSM/m/vu34w4mtqVBOpVBEpPhQMomjtdv3cte4OXyyYAPdmtfisQu70q5h9XiHJSKSb0omcZCd7bwzYyUPT15AZnY2d53ZkWuPaUlZlUIRkWJKyaSILd+0myFjU5i+dAtHt67LI+d3JalulXiHJSJSIEomRSQzK5tXvl7GE1MWUaFsGR45vwsX92iuUigiUiIomRSB+Wt3MHhMCilp2+nbsSEPnnc4jWpWindYIiKFRskkhtIzs3j2syU891kqNSuX5+lLj+Ssro11NCIiJY6SSYz8sHIrg0ensHjDLgYc2ZS7z+pEnaoV4h2WiEhMKJkUsj37M3liyiJe+XoZjWpU4tVrenBShwbxDktEJKaUTArR16mbGDI2hVVb9nJF7yQG9+9AdRVmFJFSQMmkEGzfm8FfP5jPqJmraFmvKqMG9qZXq7rxDktEpMgomRTQlLnruGv8HDbtSufGE4LCjJXKqzCjiJQucSkAZWa/M7O5ZpZtZsk5lg01s1QzW2hm/SLa+4dtqWY2JKK9pZl9F7aPMrMiucq9cWc6N7/9AwPfmEWdqhUYf/MxDD29oxKJiJRK8aomOAc4H/gistHMOhEM29sZ6A88Z2Zlzaws8CxwOtAJuDTsC/Ao8JS7twG2AtfHMnB3Z9yPaZz61H+YOnc9fzmtHe//v2Pp2kwVfkWk9IrLaS53nw9E+73FucC77p4OLDOzVKBnuCzV3ZeG670LnGtm84GTgcvCPq8Dw4HnYxF3RlY2A0fO5LOFG+meFBRmbNNAhRlFRBLtmklTYHrEfFrYBrAqR3svoC6wzd0zo/T/FTMbCAwESEpKyndw5cuWoVX9ahzfrj5X9WmhwowiIqGYJRMzmwY0irJomLtPiNXzHoy7jwBGACQnJ/uhbOPuszr9dicRkVImZsnE3fsewmqrgeYR883CNnJp3wzUMrNy4dFJZH8RESkiiTac30TgEjOraGYtgbbA98AMoG1451YFgov0E93dgc+AC8P1rwbictQjIlKaxevW4AFmlgb0AT4ws48B3H0u8B4wD/gIuNnds8KjjluAj4H5wHthX4DBwG3hxfq6wMtF+2pERMSCP+5Ln+TkZJ85c2a8wxARKVbMbJa7J+dsT7TTXCIiUgwpmYiISIEpmYiISIEpmYiISIGV2gvwZrYRWHGIq9cDNhViOIVFceWP4sofxZU/JTWuw9y9fs7GUptMCsLMZka7myHeFFf+KK78UVz5U9ri0mkuEREpMCUTEREpMCWTQzMi3gHkQnHlj+LKH8WVP6UqLl0zERGRAtORiYiIFJiSiYiIFJiSSS7M7HdmNtfMss0sOceyoWaWamYLzaxfLuu3NLPvwn6jwtL5hR3jKDP7KXwsN7Ofcum33Mxmh/1iXt3SzIab2eqI2M7IpV//cB+mmtmQIojrb2a2wMxSzGycmdXKpV+R7K/fev3hUAyjwuXfmVmLWMUS8ZzNzewzM5sXfv7/HKXPiWa2PeL9vSfWcYXPe9D3xQL/DPdXipl1L4KY2kfsh5/MbIeZ3ZqjT5HsLzN7xcw2mNmciLY6ZjbVzBaH/9bOZd2rwz6LzezqQwrA3fWI8gA6Au2Bz4HkiPZOwM9ARaAlsAQoG2X994BLwukXgD/EON4ngHtyWbYcqFeE+2448Jff6FM23HetgArhPu0U47hOA8qF048Cj8Zrf+Xl9QN/BF4Ipy8BRhXBe9cY6B5OVwcWRYnrRGBSUX2e8vq+AGcAHwIG9Aa+K+L4ygLrCH7UV+T7Czge6A7MiWh7DBgSTg+J9pkH6gBLw39rh9O18/v8OjLJhbvPd/eFURadC7zr7unuvgxIBXpGdjAzA04GRodNrwPnxSrW8PkuAt6J1XPEQE8g1d2Xuvt+4F2CfRsz7j7Fg7FxAKYTjMwZL3l5/ecSfHYg+CydEr7XMePua939h3B6J8H4QU1j+ZyF6FxgpAemE4zC2rgIn/8UYIm7H2pljQJx9y+ALTmaIz9DuX0P9QOmuvsWd98KTAX65/f5lUzyrymwKmI+jV//Z6sLbIv44orWpzAdB6x398W5LHdgipnNMrOBMYwj0i3hqYZXcjm0zst+jKXrCP6KjaYo9ldeXv9/+4Sfpe0En60iEZ5WOxL4LsriPmb2s5l9aGadiyik33pf4v2ZuoTc/6CLx/4CaOjua8PpdUDDKH0KZb/FbAz44sDMpgGNoiwa5u4JMfxvHmO8lIMflRzr7qvNrAEw1cwWhH/FxCQu4HngAYL//A8QnIK7riDPVxhxHdhfZjYMyATeymUzhb6/ihszqwaMAW519x05Fv9AcCpnV3g9bDzBENuxlrDvS3hN9BxgaJTF8dpfv+DubmYx+y1IqU4m7t73EFZbDTSPmG8WtkXaTHCIXS78izJan0KJ0czKAecDRx1kG6vDfzeY2TiCUywF+k+Y131nZi8Bk6Isyst+LPS4zOwa4CzgFA9PGEfZRqHvryjy8voP9EkL3+eaBJ+tmDKz8gSJ5C13H5tzeWRycffJZvacmdVz95gWNczD+xKTz1QenQ784O7rcy6I1/4KrTezxu6+NjzltyFKn9UE13UOaEZwrThfdJor/yYCl4R32rQk+Avj+8gO4ZfUZ8CFYdPVQKyOdPoCC9w9LdpCM6tqZtUPTBNchJ4TrW9hyXGeekAuzzcDaGvBXW8VCE4RTIxxXP2BQcA57r4nlz5Ftb/y8vonEnx2IPgsfZpbAiws4TWZl4H57v5kLn0aHbh2Y2Y9Cb5HYprk8vi+TASuCu/q6g1sjzjFE2u5nh2Ix/6KEPkZyu176GPgNDOrHZ6SPi1sy59Y32FQXB8EX4JpQDqwHvg4YtkwgjtxFgKnR7RPBpqE060Ikkwq8G+gYozifA24KUdbE2ByRBw/h4+5BKd7Yr3v3gBmAynhh7lxzrjC+TMI7hZaUkRxpRKcG/4pfLyQM66i3F/RXj9wP0GyA6gUfnZSw89SqyLYR8cSnJ5MidhPZwA3HficAbeE++ZnghsZji6CuKK+LzniMuDZcH/OJuIuzBjHVpUgOdSMaCvy/UWQzNYCGeF31/UE19g+ARYD04A6Yd9k4F8R614Xfs5SgWsP5flVTkVERApMp7lERKTAlExERKTAlExERKTAlExERKTAlExERKTAlEyk1DCzXfGOAf5bVfkv4fT9ZpbrDy3NrJtFVF02s3OsCCosi+RXqf4FvEhhCX+UZu6enZ/13P23ypF3I/hNwOSw/0Ri/OPOSGZW1t2zcpvPZZ1D2hdSvOnIREocMxsfFgOcm7MgoJk9FbZ/Ymb1w7Y/WTB+R4qZvRtle9eY2QQz+zwc7+HesL2FBeORjCT4NXZzM7vDzGaE27ovYhvDzGyRmX1FMLTBgfbXzOzCcLqHmX0TFgT83sxqEvyI8WILxsG4OIzlmYjn/zR8rk/MLClim/8Mt7X0wPajvK4rwuf5ycxeNLOyYfsuM3vCzH4mKFCYc/42M5sTPm7NbV8c0psnxVdR/EJUDz2K8sH/fuVbmeCLrW4478Dl4fQ9wDPh9BrCCgVArSjbu4bgl8V1I7aZDLQAsoHeYb/TgBEEv8QuQ1CT7HiCummzgSpADYJfGf8lXOc1glIpFQjGkegRttcgOHNwzYE4I2I5EPf7wNXh9HXA+Iht/juMoRNBqfucr6ljuH75cP454KqI/XRRRN//zke8lqpANYJfdh+Zc1/oUfoeOjKRkuhP4V/R0wn+Qj5QoTUbGBVOv0lQOgSC0iFvmdkVBNWEo5nq7pvdfS8wNmLdFR6MnQFBMjkN+JGgUmyH8LmPA8a5+x4Piv5FO03VHljr7jMgKA7o/xvCIDd9gLfD6TciYoIgsWS7+zyilx0/hSAxzLBghM5TCEqWAGQRFHokyvyx4WvZ7e67CPbFceGyyH0hpYyumUiJYmYnEhS/7OPue8zsc4IaV9EcqCV0JsERxNnAMDPrEuWLPGfdoQPzuyOfHnjY3V/MEdMvhnEtIumRIURZbsDr7h6tZPo+/+V1kZzzudn9212kpNKRiZQ0NYGtYSLpQDB86wFl+F8l58uAr8ysDNDc3T8DBofrV4uy3VMtGE+7MsFodV9H6fMxcJ0FY4FgZk0tGHvjC+A8M6scVr49O8q6C4HGZtYjXLe6BWXndxIMnxvNNwTVhgEuB77MpV80nwAXhvEdGCv8sDys9yXBa6kSVu8dkM/nlRJKRyZS0nwE3GRm8wm+oCNPu+wGeprZXQTjOlxMMG73m+HFbgP+6e7bomz3e4JTPc2AN919pgUjEf6Xu08xs47At2HF8V3AFe7+g5mNIqgau4Gg/Dw51t1vZhcDT4cJay/BEdZnwJDwVNTDOVb7f8CrZnYHsBG4Ni87KHy+eeF+mBIm1AzgZuCgQ86Gr+U1/jfswr/c/cec+0JKH1UNFvkNFgyolezut8Q7FpFEpdNcIiJSYDoyERGRAtORiYiIFJiSiYiIFJiSiYiIFJiSiYiIFJiSiYiIFNj/Bwn69+/G8wkUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TYPE                 |Almost_right |half right |extra selected |all_wrong\n",
            "jaccard_distance_loss [0.05 0.45 0.5  0.75]\n",
            "jaccard_distance_loss scaled [0.06666667 0.6        0.66666667 1.        ]\n",
            "binary_crossentropy [  3.33333333  30.          66.66666667 100.        ]\n",
            "binary_crossentropy_scaled [0.03333333 0.3        0.66666667 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44UqLqzxRdCU"
      },
      "source": [
        "# Evaluation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW82CyQfkmK0"
      },
      "source": [
        "- If start_idx pred > end_idx pred: we will take the entire text as selected_text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UnDbnZ6ERdCV"
      },
      "source": [
        "def jaccard_score(text_token_nopadding_len, start_idx, end_idx, start_pred, end_pred):\n",
        "    # start_logits, end_logits are logits output of model\n",
        "    # start_pred = np.argmax(start_logits)\n",
        "    # end_pred = np.argmax(end_logits)\n",
        "    text_len = text_token_nopadding_len\n",
        "    if start_pred > end_pred: # taking the whole text as selected_text\n",
        "        start_pred = 1\n",
        "        end_pred = text_len-1\n",
        "\n",
        "    if end_idx < start_pred or end_pred < start_idx: # intersection = 0\n",
        "        return 0\n",
        "    else: \n",
        "        union = max(end_pred, end_idx) - min(start_pred, start_idx)+1\n",
        "        intersection = min(end_pred, end_idx) - max(start_pred, start_idx)+1\n",
        "        return intersection/union\n",
        "Test =False\n",
        "if Test:\n",
        "    jaccard_score(5,1,1,4,2) # 0.25\n",
        "    # jaccard_score(96,1,1,4,2) # 0.0105\n",
        "\n",
        "    start_logits = torch.tensor([[0,0,0,0,1]]).float() \n",
        "    start_idx =torch.tensor([1])\n",
        "    #start_pred = torch.cat((start_pred, torch.zeros(1,91)),axis=1)\n",
        "\n",
        "    ce = torch.nn.CrossEntropyLoss()\n",
        "    ce(start_logits, start_idx)\n",
        "# when len=5, loss = 1.9048; when len=96, loss = 4.5718\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG4CRaE4etdd"
      },
      "source": [
        "- **Note**: \n",
        "1. jaccard_score is sensitive to total length, CrossEntropy is not sensitive.\n",
        "2. our jaccard_score function is a fast and close approximation of the true Jaccard score (character level) used in this competetion. There would be a bit more computation if we want character level Jaccard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka9RrsaLRdCZ"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tyoEEYX1RdCa"
      },
      "source": [
        "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, batch_size, filename):\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            epoch_jaccard = 0.0\n",
        "            \n",
        "            with tqdm(dataloaders_dict[phase], unit=\"batch\") as tepoch:\n",
        "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
        "                for data in tepoch:\n",
        "                    # reserve token_len, start_idx, end_idx for later loss computation\n",
        "                    token_len = data['token_len'].numpy()\n",
        "                    start_idx = data['start_idx']\n",
        "                    end_idx = data['end_idx']\n",
        "                    for key in ['token_len', 'start_idx', 'end_idx']:\n",
        "                        data.pop(key)\n",
        "                    \n",
        "                    # put data in GPU\n",
        "                    if torch.cuda.is_available():\n",
        "                        start_idx = start_idx.cuda()\n",
        "                        end_idx = end_idx.cuda()\n",
        "                        for key in data.keys():\n",
        "                            data[key]= data[key].cuda()\n",
        "\n",
        "                    # training \n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                        start_logits, end_logits = model.forward(data)\n",
        "\n",
        "                        loss = criterion(start_logits, end_logits, start_idx, end_idx)\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                        epoch_loss += loss.item() \n",
        "                        \n",
        "                        # Jaccard score\n",
        "                        #torch.argmax(torch.tensor([[0,0,0,0,1],[0,0,0,1.5,1]]), dim=1)\n",
        "                        start_pred = torch.argmax(start_logits, dim=1).cpu().detach().numpy()\n",
        "                        end_pred = torch.argmax(end_logits, dim=1).cpu().detach().numpy()\n",
        "                        \n",
        "                        start_idx = start_idx.cpu().detach().numpy()\n",
        "                        end_idx = end_idx.cpu().detach().numpy()\n",
        "\n",
        "                        for i in range(batch_size):  # or range(token_len.shape[0])                      \n",
        "                            jaccard = jaccard_score(token_len[i], start_idx[i], end_idx[i], start_pred[i], end_pred[i])\n",
        "                            epoch_jaccard += jaccard\n",
        "                    tepoch.set_postfix(loss=loss.item()/batch_size)\n",
        "                    \n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n",
        "            \n",
        "            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n",
        "                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n",
        "    \n",
        "    torch.save(model.state_dict(), filename)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czn97pW9RdCm"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WK_2s1XFRdCn"
      },
      "source": [
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5zbrcCFdM3b"
      },
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Hz6pRq_RdCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6439f861-648c-4811-fac5-22c8d5d3d0b7"
      },
      "source": [
        "%%time\n",
        "# Each fold takes 7* epochs = 35 mins,\n",
        "split_fold = False\n",
        "if split_fold:\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df_clean, train_df_clean.sentiment), start=1): \n",
        "\n",
        "        print(f'Fold: {fold}')\n",
        "\n",
        "        model = TweetModel()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
        "        criterion = loss_fn    \n",
        "        dataloaders_dict = get_train_val_loaders(train_df_clean, train_idx, val_idx, batch_size)\n",
        "        train_model(\n",
        "            model, \n",
        "            dataloaders_dict,\n",
        "            criterion, \n",
        "            optimizer, \n",
        "            num_epochs,\n",
        "            batch_size,\n",
        "            f'roberta_fold{fold}.pth')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0: 100%|██████████| 622/622 [06:11<00:00,  1.68batch/s, loss=0.0451]\n",
            "Epoch 0:   0%|          | 0/155 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5 | train | Loss: 0.0574 | Jaccard: 0.6905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 155/155 [00:27<00:00,  5.71batch/s, loss=0.0353]\n",
            "Epoch 1:   0%|          | 0/622 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5 |  val  | Loss: 0.0432 | Jaccard: 0.7367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 622/622 [06:11<00:00,  1.68batch/s, loss=0.051]\n",
            "Epoch 1:   0%|          | 0/155 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5 | train | Loss: 0.0412 | Jaccard: 0.7466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 155/155 [00:27<00:00,  5.70batch/s, loss=0.0367]\n",
            "Epoch 2:   0%|          | 0/622 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5 |  val  | Loss: 0.0408 | Jaccard: 0.7456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 622/622 [06:11<00:00,  1.68batch/s, loss=0.0389]\n",
            "Epoch 2:   0%|          | 0/155 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/5 | train | Loss: 0.0368 | Jaccard: 0.7646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 155/155 [00:27<00:00,  5.69batch/s, loss=0.0411]\n",
            "Epoch 3:   0%|          | 0/622 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/5 |  val  | Loss: 0.0427 | Jaccard: 0.7329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 622/622 [06:10<00:00,  1.68batch/s, loss=0.0335]\n",
            "Epoch 3:   0%|          | 0/155 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/5 | train | Loss: 0.0325 | Jaccard: 0.7884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 155/155 [00:27<00:00,  5.70batch/s, loss=0.0419]\n",
            "Epoch 4:   0%|          | 0/622 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/5 |  val  | Loss: 0.0460 | Jaccard: 0.7345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 622/622 [06:10<00:00,  1.68batch/s, loss=0.0333]\n",
            "Epoch 4:   0%|          | 0/155 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/5 | train | Loss: 0.0281 | Jaccard: 0.8128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 155/155 [00:27<00:00,  5.72batch/s, loss=0.0411]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/5 |  val  | Loss: 0.0491 | Jaccard: 0.7370\n",
            "Fold: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0:  32%|███▏      | 202/622 [02:00<04:11,  1.67batch/s, loss=0.0339]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1c5b720c72e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from tqdm import tqdm\\n\\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df_clean, train_df_clean.sentiment), start=1): \\n\\n    print(f'Fold: {fold}')\\n\\n    model = TweetModel()\\n    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\\n    criterion = loss_fn    \\n    dataloaders_dict = get_train_val_loaders(train_df_clean, train_idx, val_idx, batch_size)\\n    train_model(\\n        model, \\n        dataloaders_dict,\\n        criterion, \\n        optimizer, \\n        num_epochs,\\n        batch_size,\\n        f'roberta_fold{fold}.pth')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1efbf51693fd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders_dict, criterion, optimizer, num_epochs, batch_size, filename)\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRQgMtKtJqMV"
      },
      "source": [
        "- We see a increase in validation loss after 2 epochs. So we only train 2 epochs on the full data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4_Cj-nFJC9"
      },
      "source": [
        "### run on the full training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp97LFy9GP5A"
      },
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "b5d5f86533af4b01b185604a8c18cb24",
            "175ebacaa6274bcdabdabd3b2a1d9f9e",
            "e7fa1e4924a142d8816f183cf56c1c88",
            "4548474fa71842809a37e4cc9194c2bd",
            "d56309a9a3744ea6be748e6ba17d6ea7",
            "97b39b796b5646d688e993770c7985c1",
            "30201002ec3b4a66a51f1151a0f307ba",
            "9c7001fcfab54b2da57c38cb9408a44d"
          ]
        },
        "id": "G6Scb1AkFHuQ",
        "outputId": "9d84bd97-9f52-4d76-a258-e104cc3290ba"
      },
      "source": [
        "%%time\n",
        "num_epochs = 2\n",
        "batch_size = 32\n",
        "split_fold = False\n",
        "if not split_fold:\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=776*32, random_state=seed)\n",
        "    for train_idx, val_idx in sss.split(train_df_clean, train_df_clean.sentiment):\n",
        "        dataloaders_dict = get_train_val_loaders(train_df_clean, train_idx, val_idx, batch_size)\n",
        "\n",
        "    model = TweetModel()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
        "    criterion = loss_fn    \n",
        "    \n",
        "    train_model(\n",
        "        model, \n",
        "        dataloaders_dict,\n",
        "        criterion, \n",
        "        optimizer, \n",
        "        num_epochs,\n",
        "        batch_size,\n",
        "        f'roberta_whole.pth')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5d5f86533af4b01b185604a8c18cb24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1: 100%|██████████| 777/777 [07:25<00:00,  1.74batch/s, loss=0.0336]\n",
            "Epoch 1: : 0batch [00:00, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2 | train | Loss: 0.0568 | Jaccard: 0.6929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: : 0batch [00:00, ?batch/s]\n",
            "Epoch 2:   0%|          | 0/777 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2 |  val  | Loss: 0.0000 | Jaccard: 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 777/777 [07:33<00:00,  1.71batch/s, loss=0.0366]\n",
            "Epoch 2: : 0batch [00:00, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2 | train | Loss: 0.0417 | Jaccard: 0.7438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 2: : 0batch [00:00, ?batch/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2 |  val  | Loss: 0.0000 | Jaccard: 0.0000\n",
            "CPU times: user 7min 25s, sys: 7min 38s, total: 15min 4s\n",
            "Wall time: 15min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYNejTlNf2xB"
      },
      "source": [
        "del model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EX6RD_HdBxt",
        "outputId": "e346bb11-f207-40a5-d764-8ef446e80d01"
      },
      "source": [
        "# train one more epoch with lower learning rate\n",
        "sss = StratifiedShuffleSplit(n_splits=1, train_size=775*32, random_state=seed)\n",
        "for train_idx, val_idx in sss.split(train_df_clean, train_df_clean.sentiment):\n",
        "    dataloaders_dict = get_train_val_loaders(train_df_clean, train_idx, val_idx, batch_size)\n",
        "num_epochs = 1\n",
        "model = TweetModel()\n",
        "model.cuda()\n",
        "model.load_state_dict(torch.load(f'/content/drive/MyDrive/Colab Notebooks/kaggle/tweet-sentiment/roberta_whole.pth'))\n",
        "\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-6, betas=(0.9, 0.999)) \n",
        "\n",
        "train_model(\n",
        "    model, \n",
        "    dataloaders_dict,\n",
        "    criterion, \n",
        "    optimizer, \n",
        "    num_epochs,\n",
        "    batch_size,\n",
        "    f'roberta_whole2.pth')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 775/775 [07:19<00:00,  1.76batch/s, loss=0.0407]\n",
            "Epoch 1:   0%|          | 0/2 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1 | train | Loss: 0.0360 | Jaccard: 0.7712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 2/2 [00:00<00:00,  4.05batch/s, loss=0.0503]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1 |  val  | Loss: 0.0341 | Jaccard: 0.5446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXSMwFLTRdCt"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51c0369f88294a2fbcc3863bb8d39a99",
            "d4f03e4538d64566b2c2e012767320a2",
            "5b84a79d65f546558ded9a32c70a3aeb",
            "e001145491dd466f831dcd6d018247e4",
            "2fb49cf853fc418e9f4d208f18bf5932",
            "9206b4b727ed41ce8c7673320816ca27",
            "131ee625a2514ae2b084e97d09c29ac0",
            "a61b0f99badf44068ebec6370074d71f"
          ]
        },
        "id": "VSoLMeps6xqr",
        "outputId": "a1955059-3c42-4e63-b860-117406687296"
      },
      "source": [
        "# For Inference only\n",
        "# https://huggingface.co/transformers/internal/tokenization_utils.html\n",
        "\n",
        "test_df = pd.read_csv('input/tweet-sentiment-extraction/test.csv')\n",
        "test_df['text'] = test_df['text'].astype(str)\n",
        "test_loader = get_test_loader(test_df)\n",
        "\n",
        "\n",
        "model = TweetModel()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load(f'roberta_whole.pth'))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(f'roberta_whole.pth', map_location=torch.device('cpu') ))\n",
        "model.eval()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51c0369f88294a2fbcc3863bb8d39a99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TweetModel(\n",
              "  (roberta): RobertaForQuestionAnswering(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): RobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RWiPjmA_RdCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0deb5f-9b3d-4896-92e3-e06abf4ca7b5"
      },
      "source": [
        "%%time\n",
        "predictions = []\n",
        "# decode convert token ids to text\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")  \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "    tepoch.set_description(\"Test:\")\n",
        "    for data in tepoch:\n",
        "        \n",
        "        # put data in GPU\n",
        "        if torch.cuda.is_available():\n",
        "            for key in data.keys():\n",
        "                data[key]= data[key].cuda()\n",
        "\n",
        "        # testing \n",
        "        with torch.no_grad():\n",
        "\n",
        "            start_logits, end_logits = model(data)\n",
        "            start_pred = torch.argmax(start_logits, dim=1)\n",
        "            end_pred = torch.argmax(end_logits, dim=1)\n",
        "            \n",
        "            for i in range(start_pred.shape[0]): # number of rows in a batch\n",
        "                if start_pred[i] > end_pred[i]:\n",
        "                    predictions.append(' ') # those will be replace by text after we build the dataframe\n",
        "                else:\n",
        "                    sel_t = tokenizer.decode(data['input_ids'][i][start_pred[i]:end_pred[i]+1])\n",
        "                    predictions.append(sel_t)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test::   0%|          | 0/111 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::   2%|▏         | 2/111 [00:00<00:42,  2.57batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::   4%|▎         | 4/111 [00:00<00:29,  3.66batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::   5%|▌         | 6/111 [00:01<00:22,  4.65batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::   7%|▋         | 8/111 [00:01<00:19,  5.27batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::   9%|▉         | 10/111 [00:01<00:17,  5.69batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  11%|█         | 12/111 [00:02<00:16,  5.93batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  13%|█▎        | 14/111 [00:02<00:15,  6.08batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  14%|█▍        | 16/111 [00:02<00:15,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  16%|█▌        | 18/111 [00:03<00:15,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  18%|█▊        | 20/111 [00:03<00:14,  6.19batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  20%|█▉        | 22/111 [00:03<00:14,  6.17batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  22%|██▏       | 24/111 [00:04<00:13,  6.23batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  23%|██▎       | 26/111 [00:04<00:13,  6.19batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  25%|██▌       | 28/111 [00:04<00:13,  6.21batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  27%|██▋       | 30/111 [00:05<00:13,  6.19batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  29%|██▉       | 32/111 [00:05<00:12,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  31%|███       | 34/111 [00:05<00:12,  6.17batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  32%|███▏      | 36/111 [00:06<00:12,  6.15batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  34%|███▍      | 38/111 [00:06<00:11,  6.13batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  36%|███▌      | 40/111 [00:06<00:11,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  38%|███▊      | 42/111 [00:07<00:11,  6.17batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  40%|███▉      | 44/111 [00:07<00:10,  6.13batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  41%|████▏     | 46/111 [00:07<00:10,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  43%|████▎     | 48/111 [00:08<00:10,  6.17batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  45%|████▌     | 50/111 [00:08<00:09,  6.15batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  47%|████▋     | 52/111 [00:08<00:09,  6.15batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  49%|████▊     | 54/111 [00:09<00:09,  6.16batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  50%|█████     | 56/111 [00:09<00:08,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  52%|█████▏    | 58/111 [00:09<00:08,  6.14batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  54%|█████▍    | 60/111 [00:10<00:08,  6.10batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  56%|█████▌    | 62/111 [00:10<00:08,  6.09batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  58%|█████▊    | 64/111 [00:10<00:07,  6.12batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  59%|█████▉    | 66/111 [00:11<00:07,  6.06batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  61%|██████▏   | 68/111 [00:11<00:07,  6.09batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  63%|██████▎   | 70/111 [00:11<00:06,  6.13batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  65%|██████▍   | 72/111 [00:12<00:06,  6.10batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  67%|██████▋   | 74/111 [00:12<00:06,  6.11batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  68%|██████▊   | 76/111 [00:12<00:05,  6.13batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  70%|███████   | 78/111 [00:13<00:05,  6.05batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  72%|███████▏  | 80/111 [00:13<00:05,  6.08batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  74%|███████▍  | 82/111 [00:13<00:04,  6.12batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  76%|███████▌  | 84/111 [00:13<00:04,  6.12batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  77%|███████▋  | 86/111 [00:14<00:04,  6.06batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  79%|███████▉  | 88/111 [00:14<00:03,  6.07batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  81%|████████  | 90/111 [00:14<00:03,  6.07batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  83%|████████▎ | 92/111 [00:15<00:03,  6.03batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  85%|████████▍ | 94/111 [00:15<00:02,  6.00batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  86%|████████▋ | 96/111 [00:15<00:02,  6.05batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  88%|████████▊ | 98/111 [00:16<00:02,  6.11batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  90%|█████████ | 100/111 [00:16<00:01,  6.12batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  92%|█████████▏| 102/111 [00:16<00:01,  6.09batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  94%|█████████▎| 104/111 [00:17<00:01,  6.07batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  95%|█████████▌| 106/111 [00:17<00:00,  6.06batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  97%|█████████▋| 108/111 [00:17<00:00,  6.07batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test::  99%|█████████▉| 110/111 [00:18<00:00,  6.11batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTest:: 100%|██████████| 111/111 [00:18<00:00,  6.03batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.8 s, sys: 235 ms, total: 18.1 s\n",
            "Wall time: 21.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPlUWdEKRdCw"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FBvWL9cyRdCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c635ed7e-4127-48be-c055-57e988598dab"
      },
      "source": [
        "sub_df = test_df[['textID','text']]\n",
        "sub_df['selected_text'] = predictions\n",
        "def rep_text(row):\n",
        "    rst= row.selected_text\n",
        "    if (rst is ' ') or (len(rst)> len(row.text)):\n",
        "        return row.text\n",
        "    if len(rst.split())==1:\n",
        "        rst = rst.replace('!!!!', '!')\n",
        "        rst = rst.replace('..', '.')\n",
        "        rst = rst.replace('...', '.')\n",
        "        return rst\n",
        "    return rst\n",
        "\n",
        "sub_df['selected_text'] = sub_df.apply(rep_text, axis=1)\n",
        "sub_df.drop(['text'], axis=1, inplace=True)\n",
        "sub_df.to_csv('submission.csv', index=False)\n",
        "sub_df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>last session of the day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>exciting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>such a shame!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>i like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID             selected_text\n",
              "0  f87dea47db   last session of the day\n",
              "1  96d74cb729                  exciting\n",
              "2  eee518ae67             such a shame!\n",
              "3  01082688c6                     happy\n",
              "4  33987a8ee5               i like it!!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}